{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be sure to run the following notebooks first before running this notebook:\n",
    "- 1-load-and-convert-statsbomb-data.ipynb\n",
    "- 2-compute-features-and-labels.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import warnings\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "import socceraction.vaep.features as fs\n",
    "import socceraction.vaep.labels as lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configure file and folder names\n",
    "datafolder = \"../data-fifa\"\n",
    "spadl_h5 = os.path.join(datafolder, \"spadl-statsbomb.h5\")\n",
    "features_h5 = os.path.join(datafolder, \"features.h5\")\n",
    "labels_h5 = os.path.join(datafolder, \"labels.h5\")\n",
    "predictions_h5 = os.path.join(datafolder, \"predictions.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n"
     ]
    }
   ],
   "source": [
    "# Create a train and test set of games\n",
    "games = pd.read_hdf(spadl_h5, \"games\")\n",
    "games = games[games.competition_id == 43]\n",
    "traingames = games[:len(games)//2]\n",
    "testgames = games[len(games)//2:]\n",
    "print(len(traingames), len(testgames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting features: 100%|██████████| 32/32 [00:02<00:00, 12.00it/s]\n",
      "Selecting features: 100%|██████████| 32/32 [00:02<00:00, 13.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# Select shots from the data and all available info about these shots\n",
    "\n",
    "def get_shots(games):\n",
    "    shots = []\n",
    "    with pd.HDFStore(spadl_h5) as spadlstore,\\\n",
    "         pd.HDFStore(features_h5) as featurestore:\n",
    "        actiontypes = spadlstore[\"actiontypes\"]\n",
    "        for game_id in tqdm.tqdm(games.game_id, desc=\"Selecting features\"):\n",
    "            ai = (\n",
    "                spadlstore[f\"actions/game_{game_id}\"]\n",
    "                  .merge(actiontypes,how=\"left\"))\n",
    "            shot_idx = ai.type_name.str.contains(\"shot\")\n",
    "            Xi = featurestore[f\"game_{game_id}\"]\n",
    "            shots.append(Xi[shot_idx])\n",
    "    return pd.concat(shots)\n",
    "\n",
    "train_shots = get_shots(traingames)\n",
    "test_shots = get_shots(testgames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['type_pass_a0',\n",
       " 'type_cross_a0',\n",
       " 'type_throw_in_a0',\n",
       " 'type_freekick_crossed_a0',\n",
       " 'type_freekick_short_a0',\n",
       " 'type_corner_crossed_a0',\n",
       " 'type_corner_short_a0',\n",
       " 'type_take_on_a0',\n",
       " 'type_foul_a0',\n",
       " 'type_tackle_a0',\n",
       " 'type_interception_a0',\n",
       " 'type_shot_a0',\n",
       " 'type_shot_penalty_a0',\n",
       " 'type_shot_freekick_a0',\n",
       " 'type_keeper_save_a0',\n",
       " 'type_keeper_claim_a0',\n",
       " 'type_keeper_punch_a0',\n",
       " 'type_keeper_pick_up_a0',\n",
       " 'type_clearance_a0',\n",
       " 'type_bad_touch_a0',\n",
       " 'type_non_action_a0',\n",
       " 'type_dribble_a0',\n",
       " 'type_goalkick_a0',\n",
       " 'type_pass_a1',\n",
       " 'type_cross_a1',\n",
       " 'type_throw_in_a1',\n",
       " 'type_freekick_crossed_a1',\n",
       " 'type_freekick_short_a1',\n",
       " 'type_corner_crossed_a1',\n",
       " 'type_corner_short_a1',\n",
       " 'type_take_on_a1',\n",
       " 'type_foul_a1',\n",
       " 'type_tackle_a1',\n",
       " 'type_interception_a1',\n",
       " 'type_shot_a1',\n",
       " 'type_shot_penalty_a1',\n",
       " 'type_shot_freekick_a1',\n",
       " 'type_keeper_save_a1',\n",
       " 'type_keeper_claim_a1',\n",
       " 'type_keeper_punch_a1',\n",
       " 'type_keeper_pick_up_a1',\n",
       " 'type_clearance_a1',\n",
       " 'type_bad_touch_a1',\n",
       " 'type_non_action_a1',\n",
       " 'type_dribble_a1',\n",
       " 'type_goalkick_a1',\n",
       " 'bodypart_foot_a0',\n",
       " 'bodypart_head_a0',\n",
       " 'bodypart_other_a0',\n",
       " 'bodypart_head/other_a0',\n",
       " 'bodypart_foot_a1',\n",
       " 'bodypart_head_a1',\n",
       " 'bodypart_other_a1',\n",
       " 'bodypart_head/other_a1',\n",
       " 'goalscore_team',\n",
       " 'goalscore_opponent',\n",
       " 'goalscore_diff',\n",
       " 'start_x_a0',\n",
       " 'start_y_a0',\n",
       " 'start_x_a1',\n",
       " 'start_y_a1',\n",
       " 'movement_a0',\n",
       " 'dx_a1',\n",
       " 'dy_a1',\n",
       " 'movement_a1',\n",
       " 'dx_a01',\n",
       " 'dy_a01',\n",
       " 'mov_a01',\n",
       " 'start_dist_to_goal_a0',\n",
       " 'start_angle_to_goal_a0',\n",
       " 'start_dist_to_goal_a1',\n",
       " 'start_angle_to_goal_a1',\n",
       " 'team_1',\n",
       " 'period_id_a0',\n",
       " 'time_seconds_a0',\n",
       " 'time_seconds_overall_a0',\n",
       " 'period_id_a1',\n",
       " 'time_seconds_a1',\n",
       " 'time_seconds_overall_a1',\n",
       " 'time_delta_1']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decide which features to use to compute the expected goals value of the shots\n",
    "\n",
    "xfns = [\n",
    "    fs.actiontype_onehot,\n",
    "    fs.bodypart_onehot,\n",
    "    fs.goalscore,\n",
    "    fs.startlocation,\n",
    "    fs.movement,\n",
    "    fs.space_delta,\n",
    "    fs.startpolar,\n",
    "    fs.team,\n",
    "    fs.time,\n",
    "    fs.time_delta,\n",
    "]\n",
    "nb_prev_actions = 2\n",
    "\n",
    "f = fs.feature_column_names(xfns, nb_prev_actions)\n",
    "f.remove(\"dx_a0\")\n",
    "f.remove(\"dy_a0\")\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features-matrix X and label-vector y.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss, log_loss\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def Xy(f,shots):\n",
    "    return shots[f], shots.result_success_a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.773\n",
      "Brier score: 0.075\n",
      "Log loss: 0.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cw/dtaijupiter/NoCsBack/dtai/pieterr/Projects/socceraction/.venv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "X,y = Xy(f, train_shots)\n",
    "model = LogisticRegression().fit(X, y)\n",
    "\n",
    "X,y = Xy(f, test_shots)\n",
    "pred = [p[1] for p in model.predict_proba(X)]\n",
    "\n",
    "print(\"ROC AUC: %.3f\" % roc_auc_score(y, pred))\n",
    "print(\"Brier score: %.3f\" % brier_score_loss(y, pred))\n",
    "print(\"Log loss: %.3f\" % log_loss(y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cw/dtaijupiter/NoCsBack/dtai/pieterr/Projects/socceraction/.venv/lib/python3.6/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:06:39] WARNING: /tmp/pip-build-5lk6kad5/xgboost/build/temp.linux-x86_64-3.6/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC AUC: 0.819\n",
      "Brier score: 0.081\n",
      "Log loss: 0.347\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "X,y = Xy(f, train_shots)\n",
    "model = XGBClassifier().fit(X, y)\n",
    "\n",
    "X,y = Xy(f, test_shots)\n",
    "pred = [p[1] for p in model.predict_proba(X)]\n",
    "\n",
    "print(\"ROC AUC: %.3f\" % roc_auc_score(y, pred))\n",
    "print(\"Brier score: %.3f\" % brier_score_loss(y, pred))\n",
    "print(\"Log loss: %.3f\" % log_loss(y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.500\n",
      "Brier score: 0.091\n",
      "Log loss: 0.329\n"
     ]
    }
   ],
   "source": [
    "# Naive baseline, always predict class distribution\n",
    "X,y = Xy(f, train_shots)\n",
    "avgP = np.mean(y)\n",
    "\n",
    "X,y = Xy(f, test_shots)\n",
    "pred = [avgP for _i in y]\n",
    "\n",
    "print(\"ROC AUC: %.3f\" % roc_auc_score(y, pred))\n",
    "print(\"Brier score: %.3f\" % brier_score_loss(y, pred))\n",
    "print(\"Log loss: %.3f\" % log_loss(y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "socceraction",
   "language": "python",
   "name": "socceraction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
